摘要:Midjourney近期推出了名为“Omni-Reference”（全向参考）的新功能，作为其V7版本的旗舰功能，为用户提供了更大的创作自由和精准控制力。这一功能通过先进的图像参考系统，支持用户上传参考图像并精确指定元素（如人物、动物、道具等），生成结果高度匹配参考特征。其核心亮点包括多样化支持、多对象生成、灵活权重调整（通过--ow参数）以及与其他功能的生态兼容性。

Omni-Reference依托V7模型和多模态参考系统，结合CLIP-ViT与潜在扩散模型（LDM），动态调整参考影响并优化风格表现力。其应用场景广泛，涵盖叙事艺术、游戏开发、广告设计、数字艺术与教育等领域。

用户可通过Midjourney的Web或Discord平台使用该功能，需切换至V7模式并上传参考图像。社区反响积极，认为其提升了AI图像生成的一致性，但也提出了改进建议，如增强多对象解析精度。未来，Omni-Reference有望进一步扩展至视频生成和3D交互领域，成为AI艺术创作的重要里程碑。
原文url:https://www.aibase.com/zh/news/17748