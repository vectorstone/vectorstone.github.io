摘要:通义实验室自然语言智能团队近日开源了VRAG-RL，这是一款视觉感知驱动的多模态RAG推理框架，旨在解决AI在复杂视觉文档中检索和推理关键信息的难题。传统RAG方法在处理视觉内容时表现不佳，而VRAG-RL通过强化学习、视觉感知机制设计和检索与推理协同优化三个维度进行创新。它引入多样化的视觉感知动作（如区域选择、裁剪、缩放等），采用多专家采样策略和细粒度奖励机制，显著提升了模型的检索效率和推理能力。实验结果显示，VRAG-RL在多个视觉语言基准数据集上表现优异，支持多轮交互和逐步聚焦信息密集区域。该框架已在Github上开源。
原文url:https://www.aibase.com/zh/news/18546