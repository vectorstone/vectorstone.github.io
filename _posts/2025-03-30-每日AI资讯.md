摘要:Qafind Labs近日发布了其最新研发的ChatDLM模型，该模型首次将“区块扩散（Block Diffusion）”和“专家混合（MoE）”技术深度融合，实现了在GPU上2,800 tokens/s的超高推理速度和131,072 tokens的超大上下文窗口。ChatDLM采用7B参数量的架构，通过区块扩散技术和MoE机制（32-64个专家，每次选择2个）显著提升了处理速度和性能。此外，RoPE优化和分层缓存技术支持超大上下文，动态早停、BF16混合精度和ZeRO分片技术优化了多GPU扩展。性能测试显示，ChatDLM在A100 GPU上表现出色，HumanEval（0-shot）准确率达92.0%。未来，Qafind Labs计划引入自适应迭代、图注意力集成和多模态扩散等先进技术，进一步提升模型性能。
原文url:https://www.aibase.com/zh/news/17579